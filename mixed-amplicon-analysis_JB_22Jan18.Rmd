---
title: "Mixed-Amplicon paper analysis"
author: "Berry Brosi"
date: "11/30/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(knitr)
```

## Table of Contents

* A. overview
* B. data import
* C. data prep + formatting
* D. data analysis

## A. overview
there are three classes of analyses here, brief overview of each following:

1. DNA yield correlational analysis
2. False negatives (spp richness, relatedness, rarity, etc.)
3. Quantitative matching (correlational)

#### 1. DNA yield correlational analysis

* pollen DNA yields vs. genome size (Karen has already done this, probably skip?)

#### 2. False negatives: series of binomial-errors GLMMs:
For all of these, the response variable is whether or not species that were present in the mix were detected above the contamination threshold. There is typically >1 species present in each mix, so there are multiple data points per sample. In addition, detection probability is not independent of species ID. Thus, take a GLMM approach with random effects: sample ID nested within mix, and then species as a crossed random effect. Ideally, we would be able to correct for the presence of non-focal species in a mix; including 'mix' takes care of that somewhat, but imperfectly; don't know a better way to do it.

* taxonomic assignments
    + we could quantitatively assess the proportions assigned correctly overall
* species richness
* relatedness
    + right now we do not have quantitative branch lengths for relatedness
    + could do the phylogeny (potentially with the `picante` package?)
    + or could do an analysis with an ordinal Linnean predictor
* rarity

#### 3. Quantitative matching
Essentially looking at quantitative correlations between input pollen % and output sequence count %.

## B. data import
three data sets to import: 1) Illumina data for ITS2; 2) Illumina data for rbcL; 3) sample metadata

```{r data import}
ITS = read.csv("rdp_ITS2.csv")
rbcL = read.csv("rdp_rbcL.csv")
mixes = read.csv("pollen-mixes-proportions.csv")

# 'mixes' comes in with each row duplicated (because in the spreadsheet, each was assessed with both ITS2 and with rbcL); fix this here:
mixes = unique(mixes)


# check them out to make sure we're all good:
# View(ITS)
# View(rbcL)
# View(mixes)
```

**note** because of the duplication (ITS2 + rbcL), I found one error in the data: in original data, *Zea mays* in mix 13 had two conflicting values, 0.22 and 0.02. In looking at the proportions of the other species in mix 13, it's clear that this should be 0.02. I changed this in the original data (.csv file).


## C. data formatting / setup

* C.1 Overview
* C.2 Illumina data
* C.3 combine Illumina & sample data

### C.1 Overview

#### Illumina data (C.2):

  1. split taxonomy column so we can ascertain the taxonomic matching at multiple levels (species / genus / family)
  2. remove taxa below the isolation / PCR negative control thresholds
      1) this entails removing whole rows
  3. remove reads below the isolation / PCR negative control threshold
      1) a separate issue is for taxa that are above the threshold but which have reads in some samples below the threshold; convert these to zero as they are essentially meaningless
  4. for this analysis, remove negative control columns?

#### combine Illumina & sample / mix data (C.3)
new aggregated datasheeet, based on sample metadata, but which matches sample data back to the Illumina data (for both *rbcL* and ITS2) so we can run analyses about likelihood of matching (both qualitative and quantitative)

* sample identifiers (from sample data):
    + mix (repeated rows for each sample and each species within a sample)
    + sample (repeated rows for each species within a sample)
    + species
    + genus
    + family
    + which questions the mix is relevant to (see below); given that some mixes are used to answer multiple questions, need three separate columns
    + **note** *we may wish to assess genus / family in separate datasheets as in some mixes there are multiple species in the same genus or family*
* predictor / independent variables (from sample data):
    + Question 1: species richness
    + Question 2: rarity (actual proportion of grains this taxon has in a sample)
    + Question 3: taxonomic relatedness (need to figure out how to code it)
* response variables: **these are generated by matching sample identifiers with Illumina data**
    + presence / absence match (one column each for ITS2 and *rbcL*)
    + quantitative match (based on sequence counts; again, one column each for ITS2 and *rbcL*)

### C.2 data formatting: Illumina

#### C.2.1 Illumina: split taxonomy & clean up

* use the 'colsplit' function from the 'reshape2' require
* trim characters off the front and the back (more complex than it might seem...)

```{r split taxonomy column + clean up}
require(reshape2)

# first need to set up a vector of column names to split the taxonomy column into:
namer = c("kingdom","phylum","class","order","family","genus","species")

# now actually split the column into many
# put into a new dataframe called "taxonomy"
taxonomy.rbcL = colsplit(rbcL$tax.cat, ";", namer)
taxonomy.ITS = colsplit(ITS$tax.cat, ";", namer)
# View(taxonomy.rbcL) # worked

# trim taxonomy names within columns of excess characters before and after
# use 'substr'; define custom function and then use 'apply' across multiple columns
# trim first 3 characters; the length of last characters to trim is variable
# so reverse the string and then look for the first match
# almost certainly a faster / cleaner way to do this!
tax.substr = function(X) {
  n = nchar(X) # count number of characters
  # find where the last "_" in the string is; first reverse a temp copy of the string
  Y = strsplit(X, NULL)[[1]] # split string up into individual characters
  Y =  rev(Y) # reverse the order of the individual characters
  Y = paste(Y, collapse='') # collapse them back into a string
  end.trim = gregexpr("_",Y)[[1]][1] # returns the very first match for "_" (in the reversed string)
  end.trim = n - end.trim # where to cut string off at the end
  substr(X,4,end.trim) # trim string on both ends
}

# apply the trimming function to the two "taxonomy" files
taxonomy.rbcL = apply(taxonomy.rbcL, c(1,2), tax.substr)
taxonomy.ITS = apply(taxonomy.ITS, c(1,2), tax.substr)
# View(taxonomy.ITS) # works (after some pain)

# now add the taxonomy columns back in to the original dataset
rbcL = cbind(taxonomy.rbcL, rbcL)
ITS = cbind(taxonomy.ITS, ITS)

# delete the 'tax.cat' column as it takes up a huge amount of space
# double-check that 'tax.cat' is in the 8th column (should be, given that length(namer)==7)
# data.frame(names(rbcL))[1:12,] # yes.
rbcL = rbcL[,-8]
ITS = ITS[,-8]
# View(rbcL) # looks good.
# View(ITS) # looks good.

# cleanup
rm(namer, taxonomy.rbcL, taxonomy.ITS)

```


### C.2.2 remove taxa below contamination threshold

overview: 

* identify which columns contain negative controls
* identify threshold: find maximum count number in those negative control columns
* identify rows (taxonomic matches) which have no count higher than the threshold
* remove those rows

```{r remove taxa below contamination threshold}

# first find negative control columns
neg.controls.rbcL = grep("neg", names(rbcL)) # identifies negative control columns
# negative controls are columns 17, 19, and 20
neg.controls.ITS = grep("neg", names(ITS))

# establish threshold (identify the maximum across all of those columns):
maxy.rbcL = max(rbcL[,neg.controls.rbcL])
maxy.ITS = max(ITS[,neg.controls.ITS])
# max(c(max(tax[,17]),max(tax[,19]),max(tax[,20]))) # test to compare; works

# now remove any row for which the sum of sequence reads is < maxy:
# do it only for numeric columns; first we have to identify those
nums.rbcL <- data.frame(sapply(rbcL, is.numeric)) # logical if columns are numeric
nums.ITS <- data.frame(sapply(ITS, is.numeric)) # logical if columns are numeric

nums.rbcL = which(nums.rbcL==TRUE) # picks only the numeric columns
nums.ITS = which(nums.ITS==TRUE) # picks only the numeric columns

# determine which rows to get rid of... 
indexy.rbcL = which(rowSums(rbcL[,nums.rbcL]) < maxy.rbcL)
indexy.ITS = which(rowSums(ITS[,nums.ITS]) < maxy.ITS)
# length(indexy.rbcL)
# length(indexy.ITS)

# get rid of rows under the threshold!
rbcL = rbcL[-indexy.rbcL,]
ITS = ITS[-indexy.ITS,]

# cleanup
# don't remove 'nums', 'maxy', & 'neg.controls' as these may be useful subsequently 
rm(indexy.rbcL, indexy.ITS)

```

### C.2.3 remove reads below the isolation / PCR negative control threshold

a separate issue from the above is for *taxa* that are above the threshold but which have *reads* in some samples below the threshold; convert these to zero as they are essentially meaningless.

**unclear if we want to do this; we may want to assess with and without this step**


```{r remove reads below threshold}

# how many of those are less than the threshold?
# a non-trivial number of reads...!
# length(which(rbcL[,nums.rbcL] < maxy.rbcL & rbcL[,nums.rbcL] > 0)) #1,550 
# length(which(ITS[,nums.ITS] < maxy.ITS & ITS[,nums.ITS] > 0)) #1,824

# now remove those values below the threshold (i.e. convert them to zeros)
# try it with a copy of the data (temp.tax)
temp.rbcL = rbcL[,nums.rbcL]
temp.rbcL[temp.rbcL < maxy.rbcL & temp.rbcL > 0] = 0

temp.ITS = ITS[,nums.ITS]
temp.ITS[temp.ITS < maxy.ITS & temp.ITS > 0] = 0

# length(which(temp.rbcL < maxy.rbcL & temp.rbcL > 0))
# 0 -- it worked

# now do it for the actual data (by copying the temp data)
rbcL[,nums.rbcL] = temp.rbcL
ITS[,nums.ITS] = temp.ITS
rm(temp.rbcL, temp.ITS) # save some space

```

#### C.2.4 remove negative controls

very straightforward: just remove these columns, since they don't actually include any real data.

```{r remove negative controls}
# pretty straightforward; we previously identified which columns were the negative controls
rbcL = rbcL[,-neg.controls.rbcL]
ITS = ITS[,-neg.controls.ITS]

```

### C.3 data formatting: create new aggregated datasheet
#### C.3.1 set up backbone of new aggregated datasheet + rename Illumina columns

* sample metadata ('mixes') data already imported; this will form the backbone of this new aggregated datasheet
* mix metadata does not include sample identifiers, so we will need to get mix and sample IDs from Illumina, use that as the row backbone for the new aggregated datasheet, and then fill in the rest based on matching with metadata (using `merge` command)
* to get sample IDs, transpose the column names from the Illumina data (after some trimming)
* also need to change the column names in the Illumina datasets so they match with the sample data (i.e. following the trimming suggested above)

In theory, column names (i.e. sample identifiers) should be the same for the ITS and *rbcL* data; I double-checked this (repeating the steps in the R code chunk below) and found that they matched exactly, including their order; I deleted this code for streamlining purposes. Thus, below I have only done this for *rbcL* because it is equivalent to ITS2.

```{r sample and mix IDs from Illumina}
# put column names into a temporary vector:
# the 'nums.rbcL' vector unfortunately doesn't work after we deleted negative controls from the data
# hence we start with the first value of 'nums' and then go to the last column of the dataset:
temp = names(rbcL[min(nums.rbcL):ncol(rbcL)])

# trim column names; all have a superflous '_L001_R1_001' (12 characters) at the end
# easier than previous trimming (thank goodness!)
# function to trim:
col.substr = function(X) {substr(X,1,nchar(X)-12)}

# apply the trimming function over the data, convert to data.frame
temp = data.frame(sapply(temp, col.substr))
row.names(temp) = 1:nrow(temp) # rename row names; unnecessary, but reduces confusion
names(temp) = "label" # rename column name

# create new column names
namer = c("mix.ID", "sample")

# split columns, create new dataframe in process... 
agg = colsplit(temp$label, "_", namer)

#############################
# a second component here is to actually re-name the columns in the rbcL and ITS dataframes, so that they can later be matched to the sample data
# note that the names are equivalent in the rbcL and ITS datasets, so we can use 'temp' to rename both
names(rbcL)[min(nums.rbcL):ncol(rbcL)] <- as.character(temp[,1])
names(ITS)[min(nums.ITS):ncol(ITS)] <- as.character(temp[,1])

```

#### C.3.2 merge Illumina data & metadata

use 'mix.ID' as the variable to combine by...

```{r merge Illumina and metadata}

agg =  merge(agg, mixes, by = "mix.ID")
# easy enough!

# create a new column that is 'mix' and 'sample' concatenated, for later use in matching with the Illumina data (this mirrors the column headers of the Illumina data, post re-naming in the step above)
agg$sample.mix = paste(agg$mix.ID, agg$sample, sep = "_")

```

#### C.3.3 split Illumina data into species, genus, family datasheets
one non-trivial issue is that taxa are repeated (multiple rows) in the Illumina data. In theory, this should not happen for species, at least typically (though it is at least theoretically possible--if unlikely--that the OTU algorithm could split out two OTUs from the same species, that the taxonomy classifier could subsequently classify as the same thing).

To deal with this, create three different dataframes for each marker, one each for species, genus, and family. For each of those: 

* discard all data without a match at the given taxonomic level;
* then use `dplyr` to sum read counts across redundant taxa names (use the `summarize` function)

use a nested `for` loop approach for this, with the two above steps constructed as text strings with `paste` and then those arguments evaluated using `eval`

```{r split Illumina data into taxon-specific datasets}
require(dplyr)

taxon = c("species", "genus", "family")
marker = c("rbcL", "ITS")

for(k in 1:length(taxon)){ # 'taxon': species, genus or family
  for(j in 1:length(marker)) { # 'marker': rbcL or ITS2
    # first, discard all data without a match at the given taxonomic level:
    discarder = paste(marker[j], ".", taxon[k], " = filter(", marker[j], ", ", taxon[k], "!= \"\")", sep = "")
    eval(parse(text = discarder))
    # then, sum read counts across redundant taxa rows:
    summarizer = paste(marker[j], ".", taxon[k], " = ", marker[j], ".", taxon[k], " %>% select(", taxon[k], ", 9:ncol(", marker[j], ".", taxon[k], ")) %>% group_by(", taxon[k], ") %>% summarize_all(sum)", sep = "")
    eval(parse(text = summarizer))
  }
}

```

#### C.3.4 match Illumina data to sample data, qualitatively & quantitatively

* select the row by matching with the taxon ID; if NA, then no match
* select the column by matching with the sample / mix ID
* with row and column data, return the value of that cell (proportion of column total, i.e. proportion of matching reads for that sample); return 0 for non-matches
* then create a separate qualitative match which can be based on the quantitative match (i.e., if quant match > 0)
* we will need to repeat the quant and qual each 6x; once for {family, genus, and species} for each of {ITSs and *rbcL*}
* i.e. 12 columns in total
* use a nested `for` loop approach, with taxon / marker / dataset row 


```{r match Illumina to sample data}

# first set up a dataframe to hold the results; later can 'cbind' this to our data
# step 1: generate setup for naming columns automatically using 'expand.grid'
# there is almost certainly a more efficient way to do this!
bob = expand.grid(qq = c("quant","qual"), taxon = c("species","genus","family"), marker = c("rbcL", "ITS"))
# step 2: create dataframe full of zeros, of the right size:
results = data.frame(matrix(data = 0, nrow = nrow(agg), ncol = 12))
# step 3: rename with correct names by combining the names from step 1
names(results) = paste(bob$qq, bob$taxon, bob$marker, sep = ".")
rm(bob) # get rid of unnecessary dataframe holding name components

# now nested 'for' loop (taxon / marker / rows of dataset) for matching, first with row and then with column; importantly, need to match to the correct dataframe by taxon

for(k in 1:3){ # 'taxon': species, genus or family
  for(j in 1:2) { # 'marker': rbcL or ITS2
    for(i in 1:nrow(agg)){ # cycles through the rows of the dataset
      # first, match to the row ('ro'):
      name.ro = paste('ro = match(agg$', taxon[k], "[i], ", marker[j], ".", taxon[k], "$", taxon[k], ")", sep = "")
      ro = eval(parse(text = name.ro))
      # second, match to the column ('col'):
      name.col = paste("col = match(agg$sample.mix[i], names(", marker[j], ".", taxon[k], "))", sep = "")
      col = eval(parse(text = name.col))
      # third, put row and column together to generate the actual quantitative match:
      quanter = paste(marker[j], ".", taxon[k], "[", ro, ", ", col, "]", sep = "")
      # want to return 0 if no match (i.e. if either ro or col is NA)
      quant = as.double(ifelse(is.na(col) == T | is.na(ro) == T, 0, eval(parse(text = quanter))))
      # also need to divide by column sum to get proportions
      colsum.txt = paste("colSums(", marker[j], ".", taxon[k], "[,", col, "])", sep = "")
      colsum = as.double(eval(parse(text = colsum.txt)))
      quant = quant / colsum
      # fourth, put that quantitative match in the right place in the 'results' dataframe:
      resulter = paste("results$quant.",taxon[k], ".", marker[j], "[i] = quant", sep = "")
      eval(parse(text = resulter))
    }
  }
}

# now do the qualtitative matches:
for(k in 1:3){ # 'taxon': species, genus or family
  for(j in 1:2) { # 'marker': rbcL or ITS2
    # first, generate index of which are qualitative matches:
    indexier = paste("indexy = which(results$quant.", taxon[k], ".", marker[j], " > 0)", sep = "")
    eval(parse(text = indexier))
    # then, change those entries to 1s in the 'results' dataframe:
    resultier = paste("results$qual.", taxon[k], ".", marker[j], "[indexy] = 1", sep = "")
    eval(parse(text = resultier))
  }
}

# finally, append the 'results' data onto the 'agg' data to create final dataframe to use for analyses:
agg = cbind(agg, results)


```

## D. data analysis 

### D1. False negative analysis: proportion of samples that correctly report true positives

given the focus on false negatives, response here is qualitative match.

mixed-effects modeling approach throughout. sample nested within mix `(1|mix.ID/sample)` throughout, crossed with taxon e.g. `(1|species)`, `(1|genus)`, `(1|family)`. Given qualitative match, use a binomial-errors approach

treat each taxonomic level and each marker (*rbcL* vs. ITS2) separately

three questions: 

* Question 1: species richness
* Question 2: rarity (actual proportion of grains a taxon has in a sample)
* Question 3: taxonomic relatedness

#### first task: set up different data subsets for the analyses
just summarize data for taxonomic level. During the data analysis step, we can subset each of these datasets. Since the data are summarized (literally summed) for genus and for family, we need to have separate datasets for them. Better to have only 3 datasets kept in memory.

```{r D1 data subsetting}
write.csv(agg,"aggincZea.csv")
# take out Zea for now:
agg = filter(agg, genus!="Zea")

# species
data.species = agg

# genus
# with this approach, columns get re-arranged but shouldn't matter
data.genus = agg %>% select(sample.mix, genus, 13:ncol(agg)) %>% group_by(sample.mix, genus) %>% summarize_all(sum)
data.genus = merge(data.genus, agg, all.x = T, all.y = F)
# remove additional too-fine taxonomic identifiers for clarity:
data.genus = select(data.genus, -species)

# family
data.family = agg %>% select(sample.mix, family, 13:ncol(agg)) %>% group_by(sample.mix, family) %>% summarize_all(sum)
data.family = merge(data.family, agg, all.x = T, all.y = F)
# remove additional too-fine taxonomic identifiers for clarity:
data.family = select(data.family, -species, -genus)

```

#### D1 Analyses

Decided to set up one `for` loop for all of the various analyses, since there are 36 of them altogether:

* 3 questions (spp.rich, pollen.grain.proportion, relatedness)
* 3 taxonomic levels (species, genus, family)
* 2 markers (rbcL, ITS2)
* 2 data subsets (either all data, or just the subset designed for the question)

**NOTES** 

* for the time being I have removed *Zea* from the analyses as it seemed to be screwing things up
* I also am not currently running models for the 'family' taxonomic level as in some cases there was no variance in the data (all correct identifications)


```{r D1.1 pooled analyses}
require(lme4)

# first set up a table for the results:
# I will set this up with 36 entries, but only fill in 24 (since we are skipping the 'family' level for the time being)
results.table = data.frame(question = rep(NA,36), taxon  = rep(NA,36), marker  = rep(NA,36), data.subset  = rep(NA,36), model.name = rep(NA,36), p.val  = rep(1.000001,36), n  = rep(9999,36), warning.msg = rep(NA,36))

# keep track of which row of the table to record in:
tracker = 1

# # EXAMPLE FORMULA
# Q1.species.rbcL.sub = glmer(qual.species.rbcL ~ spp.rich + (1|mix.ID/sample) + (1|species), family = binomial, data = data.species, control = glmerControl(optimizer="bobyqa"))
# summary(Q1.species.rbcL.sub)

# basis of subsetting:
# sub = filter(data, question.1 ==1 | question.2 ==1 | question.3==1)
datasubset = c("sub", "all") # whether we are using the designated subset of data designed for the question, or all data

# response variables relating to each of the three questions (column names in data)
question = c("spp.rich", "pollen.grain.proportion", "relatedness")

for(q in 1:3) { # 'question': response variables for Q1 / Q2 / Q3
    # FOR NOW ONLY DOING SPECIES AND GENUS, SINCE FAMILY SOMETIMES HAS 100% MATCHING
    for(k in 1:2){ # 'taxon': species, genus ** (SET TO K in 1:3 to include FAMILY)! **
    for(j in 1:2) { # 'marker': rbcL or ITS2
      for(l in 1:2) { # 'datasubset': sub or all
        # first, name the analysis:
        namer = paste("Q", q, ".", taxon[k], ".", marker[j], ".", datasubset[l], sep = "")
        # # 1.5, print name of which model was evaluated
        # print("**************************************************")
        # print(paste("*********************     ", namer, "     *********************"))
        # print(paste("question q = ", q, "; taxon k = ", k, "; marker j = ", j, "; datasubset l = ", l))
        # print("**************************************************")
        # second, set which taxonomic data to use:
        data.to.use = paste("data.", taxon[k], sep = "")
        # third, set up the data subset (may or may not use)
        subster = paste("data.sub = filter(", data.to.use, ", question.1 == ", q, " | question.2 == ", q, " | question.3 == ",q, ")", sep = "")
        eval(parse(text = subster)) # probably not the most efficient thing ever... 
        # fourth, set whether or not data subset is used (vs. all data)
        if(datasubset[l]=="sub") {data.to.use = "data.sub"} # i.e., doesn't change if all data are to be            used
        # fifth, set up mixed-effects model: 
        mixed = paste(namer, " = suppressWarnings(glmer(qual.", taxon[k], ".", marker[j],
          " ~ ",  question[q], " + (1|mix.ID/sample) + (1|", taxon[k], "), family = binomial, 
          data = ", data.to.use, ", control = glmerControl(optimizer=\"bobyqa\")))", sep = "")
        # sixth, evaluate the mixed-effects model
        eval(parse(text = mixed))
            # # eighth, print summary of model [SKIP FOR NOW]
            # summarizer = paste("print(summary(", namer, "))", sep = "")
            # eval(parse(text = summarizer)) # print summary of the mixed-effects model
        
        ## extract p-value
        # example: coef(summary(Q3.genus.ITS.all))[2,4]
        pvaller = paste("pval <- coef(summary(", namer, "))[2,4]", sep = "")
        eval(parse(text = pvaller))
        
        # extract convergence failures
        converger = paste(namer, "@optinfo$conv$lme4$code", sep = "")
        converg = eval(parse(text = converger))
        converg.return = ifelse(length(converg)==1, "ERROR!!", "")
        
        # record results in table
        results.table[tracker,1] = question[q]
        results.table[tracker,2] = taxon[k]
        results.table[tracker,3] = marker[j]
        results.table[tracker,4] = datasubset[l]
        results.table[tracker,5] = namer
        results.table[tracker,6] = pval
        results.table[tracker,7] = nrow(eval(parse(text = data.to.use)))
        results.table[tracker,8] = converg.return
        
        # advance tracker
        tracker = tracker + 1
      }
    }
  }
}

```

*note: warning messages suppressed for neatness. Any model with convergence errors is noted in the table below*

## RESULTS: mixed-effects models for qualitative matching

**REMEMBER: THESE DATA DO NOT INCLUDE ZEA**

**TAKE-HOME MESSAGE:** None of the factors we examined is a statistically important driver of qualitative matching. Just two models without problems / errors were statistically significant: 

* `Q2.genus.rbcL.all`---rarity / proportion of pollen grains, matched at the genus level, for *rbcL* and including all data (not just the subset of data focused on rarity)
* `Q3.genus.rbcL.all`---relatedness, matched at the genus level, for *rbcL* and including all data (not just the subset of data focused on relatedness)

It is worth noting that the models that used all the data included the single-species data as well as the mixes. I think that we should largely focus on the **subset** models, as they were designed with the questions in mind.

More detail on any particular model can be obtained by typing "summary(model)" in the console, and replacing 'model' with the model name from the 'model.name' column in the results table below.

```{R display results}
# display results table
# note that the 'kable' function is part of the 'knitr' package, which I required at the very top of this document. 
kable(results.table[1:24,])
```

## 3. Quantitative Matching

Note that while it is important to assess if there is a statistical relationship between input pollen grain proportion and output proportion of sequence reads, evidence of such a relationship does not mean that metabarcoding is quantitative. If metabarcoding were quantitative, we would want a very high $R^{2}$ value, not only a low $p$-value. My *a priori* expectation is that there will be a statistically significant relationship between input pollen grain proportion and output proportion of sequence reads.

Quantitative matching is more straightforward than the qualitative matching. We want to use all of the data (no particular subset, though potentially could have used the rarity analysis; but this question is relevant whenever metabarcoding is applied). Just four results: {species and genus} x {rbcL and ITS2}. Use a linear mixed-effects modeling approach with the `lmerTest` package to generate $p$-values, with `mix.ID` and `species` as crossed random effects. Proportion of sequence reads is the response variable, and pollen grain proportion going in is the sole fixed effect.

*May want to add in some code to assess $R^{2}$ values for these models. This is somewhat complex philosophically for mixed-effects models, and a couple of different ways of doing it, but my thought would be to try a couple of different ways.*

```{R quantitative matching}
require(lmerTest)

# ultimately want 4 analyses: {species and genus} x {rbcL and ITS2}
# rbcL species
quant.rbcL.species = lmer(quant.species.rbcL ~ pollen.grain.proportion + (1|mix.ID) + (1|species), data = data.species)
# summary(quant.rbcL.species)

# rbcL genus
quant.rbcL.genus = lmer(quant.genus.rbcL ~ pollen.grain.proportion + (1|mix.ID) + (1|genus), data = data.genus)
# summary(quant.rbcL.genus)

# ITS2 species
quant.ITS.species = lmer(quant.species.ITS ~ pollen.grain.proportion + (1|mix.ID) + (1|species), data = data.species)
# summary(quant.ITS.species)

# ITS2 genus
quant.ITS.genus = lmer(quant.genus.ITS ~ pollen.grain.proportion + (1|mix.ID) + (1|genus), data = data.genus)
# summary(quant.ITS.genus)

```

#### Results of quantitative matching

All four models are highly statistically significant, $p < 2^{-07}$ at a maximum. Thus, there is a statistically significant relationship between input pollen grain proportion and output proportion of sequence reads. Again, that is not evidence of metabarcoding being quantitative.


## 4. GRAPHS

Want the plots to inform our particular questions:

* Question 1: species richness (integer, 1-9 species)
    + potentially mean with binomial CI of % matched, with species richness on X?
    + box-and-whisker plots don't seem to work well (played around with them) because everything ranges from zero to one. binomial CIs are much better
* Question 2: rarity (continuous, actual proportion of grains a taxon has in a sample)
    + potentially model fits from logistic regressions?
* Question 3: taxonomic relatedness (integer: 0 = one species in sample; 1 = congeneric; 2 = same family; 3 = same class; 4 = different classes)
    + potentially mean with CI of % matched, with relatedness on X?

In general I think it makes the most sense to create plots based on the data subsets we created for particular questions, as opposed to using all of the data

We can make plots based on species matching and based on genus matching, and for the two different markers (ITS2 and *rbcL*). Thus, four different possible plots for each question. Probably go ahead and make all 4, and then use just two for each question (at one taxonomic level, but for both markers).


### Data prep for graphs

basically need to create mean and binomial CI for each level of both spp richness and relatedness. Given that there are different levels, and different data subsets involved, create these separately for the two questions / responses (richness and relatedness). Within each of those two datasets, we want to summarize the data for each of the four graphs we want to create (for the two markers, and two levels of taxonomic matching). 

To do this right, we need to summarize 3x---once for sample, once per mix, and then by each factor we are interested in (spp rich or relatedness). Otherwise samples with multiple species will get over-represented in terms of the overall means. We will keep track of integers at each step, and will do the summarizing with `dplyr`. We will summarize with `dplyr` twice, once per mix and then once per sample. Then within each level of the factor of interest, we will summarize with `metafor` (for those levels with multiple samples per level) or with `binom` (for those levels with just one sample per level).

* `metafor` package: computing the "exact" 95% CIs using the `binom.test()` function and then passing those bounds to `forest()`
    + https://stackoverflow.com/questions/36967850/using-metafor-or-meta-for-meta-analysis-of-proportions
    + this only works for those data that are replicated within each level of the factor, e.g. if there are multiple observations with species richness == 2, but fails if not replicated within level
    + in that case, pooling doesn't matter, so use the `binom` library to just create standard binomial CIs
* I tried these two packages but couldn't get them to work:
    * package `binomSamSize` for calculating binomial pooled CIs with the `poolbinom.logit` function.
    * `binGroup` package, `pooledBin` function
* looks like what we want to do is have `dplyr` summarize the data such that we have
    + sums of positive IDs for each species within each sample
    + number of species within each sample
    

```{r data prep for graphs}
require(dplyr)
require(binom)
# require(binomSamSize)
# require(binGroup)
require(metafor)

# 'pooledBin' function example
# returns a single point estimate + upper & lower CIs for the pooled data (exactly what we want) 
    # Consider an imaginary example, where pools of size
    # 1, 5, 10 and 50 are tested, 5 pools of each size
    # among the 5 pools with size 1 and 5, no pool is positive,
    # while among the 5 pools of size 10 and 50, 1 and 2 positive
    # pools are identified, respectively.
    
    # x1 <- c(0,0,1,2) # positive counts (number of positive pools)
    # m1 <- c(1,5,10,50) # size of pools
    # n1 <- c(5,5,5,5) # number of each pool of a given size
    
    # n1 <- c(1,1,1,1) # (didn't work)
    # !! NOTE !!: each value of n must be at least as big or bigger than the corresponding value of x 
    # pooledBin(x=x1, m=m1, n=n1)

# # so basically we need to feed it one dataset for each level of species richness
# rich.2 = filter(data.rich.plots, spp.rich==2)
# rich.2.binom = pooledBin(x = rich.2$species.ITS, m = rich.2$num, n = rep(1, nrow(rich.2)))

# one issue: we have taken Zea out of the data, so species richness numbers are not accurate
# however, by calculating the n for each sample we can correct for that easily

# calculate pooled binomial CIs with the `poolbinom.logit` function

# first, summarize by spp.rich, mix.ID, sample:
# calculate pool size for each sample ('n()'), as well as sum # of positive identifications
CI.data.1 = data.species %>% 
select(mix.ID, sample, spp.rich, qual.species.rbcL, qual.species.ITS, qual.genus.rbcL, qual.genus.ITS) %>% group_by(spp.rich, mix.ID, sample) %>% 
summarize(pool.size = n(),
  species.ITS = sum(qual.species.ITS), 
  species.rbcL = sum(qual.species.rbcL), 
  genus.ITS = sum(qual.genus.ITS), 
  genus.rbcL = sum(qual.genus.rbcL))

  # mix.15 = filter(data.rich.plots, mix.ID == "mix15")

  # d = poolbinom.logit(mix.15$species.ITS, mix.15$num, rep(prod(mix.15$num), 3))
  # d = poolbinom.logit(mix.15$species.ITS, mix.15$num, mix.15$num)
  # d = poolbinom.logit(data.rich.plots$species.ITS, data.rich.plots$num, data.rich.plots$num)

  # d = pooledBin(data.rich.plots$species.ITS, data.rich.plots$num, data.rich.plots$num)

# second step: group_by(spp.rich, mix.ID, pool.size)
CI.data.2 = CI.data.1 %>% group_by(spp.rich, mix.ID, pool.size) %>% 
  summarize(pool.num = n(),
  species.ITS = sum(species.ITS), 
  species.rbcL = sum(species.rbcL), 
  genus.ITS = sum(genus.ITS), 
  genus.rbcL = sum(genus.rbcL)) # %>% 
  # multiply pool size & number to get total number of possibilities of matches
  CI.data.2$n2 = CI.data.2$pool.size * CI.data.2$pool.num
  
  write.csv(CI.data.2, file="mixed_amp_data_for_figs.csv")
  # mutate(n.2 = as.integer(pool.size)*as.integer(pool.num))) 


# now that we have summarized the data, time to get the actual values
# 1. set up a results table to dump results into
# 2. 'for' loop running through each level of species richness (1:9)
# 3. put results into table
# 4. 


# 1. set up a results table to dump results into
  # we want to repeat this for:
  #   - 2 levels of species richness (only ones that are replicated with different mixes in the dataset)
  #   - 2 markers (rbcL and ITS2)
  #   - 2 taxonomic levels (species and genus) # START OUT WITH JUST SPECIES
# starter = expand.grid(spp.rich = 1:9, taxon = c("species", "genus"), marker = c("rbcL", "ITS"))
starter = expand.grid(spp.rich = 1:2, taxon = c("species"), marker = c("rbcL", "ITS"))

# run a GLMM with metafor to get data to use 
meta.sp.rbcL <- rma.glmm(measure="PLO", xi=species.rbcL, ni=n2, data=CI.data.2)
# actual predictions (easy!)
bob = predict(meta.sp.rbcL, transf=transf.ilogit)
# use them to create a data frame with 9 rows:
resultsier = data.frame(matrix(data = rep(bob,nrow(starter)), nrow = nrow(starter), byrow = T))
# match names of data frame to predictions
names(resultsier) = names(bob)
# then get rid of 'bob' for cleanup:
rm(bob)
# pull out only the mean and upper / lower CIs:
resultsier = resultsier[,c(1,3:4)]

# merge 'starter' and 'resultsier':
resultsier = cbind(starter, resultsier)

# set vals of resultsier to be very low, so we can tell when they've been changed:
resultsier[,4:6] = rep(0.00001, nrow(resultsier))

# # test glmm:
# meta <- rma.glmm(measure="PLO", xi=species.rbcL, ni=n2, data=CI.data.2)
# temp = as.data.frame(predict(meta, transf=transf.ilogit))

# 2. and 3. set up 'for' loop to generate results, put them into a table
# taxon = c("species", "genus") 
# not using the above for the moment as 'genus' is not working--no variance in at least one level of species richness
taxon = "species"
marker = c("rbcL", "ITS")
counter = 1

for(i in 1:2){ # species = i HERE THIS IS JUST FOR SPECIES RICHNESS of 1 and 2
  for(j in 1:length(taxon)) { # taxon = j # here this is just for species, not genus (j = 1)
    for(k in 1:length(marker)) { # marker = k # = 2 (ITS & rbcL)
      # set up text string of model to run; 'rma.glmm' function from 'metafor' package:
      # probably would be better to set this up with explicit random effects, but oh well...
      temp.expr = paste("meta <- rma.glmm(measure=\"PLO\", xi = ", 
                        taxon[j], ".", marker[k], ", ni=n2, data = filter(CI.data.2, spp.rich == ",
                        i, "))", sep = "")
      # run the model via evaluation:
      eval(parse(text = temp.expr))
      # pull out mean / CI predictions:
      temp = as.data.frame(predict(meta, transf=transf.ilogit))
      temp = temp[,1:3]
      # put results into the results table:
      resultsier[counter,4:6] = temp
      # put correct levels into results table, (just to be sure):
      resultsier[counter,1] = i # species richness
      resultsier[counter,2] = taxon[j] # taxon
      resultsier[counter,3] = marker[k] # marker
      # advance counter
      counter = counter + 1
    }  
  }
}

# 4. use 'binom' package to generate the mean and CIs for the other levels of spp rich
# (those greater than 2)
require(binom)
spp.rich.3plus = filter(CI.data.2, spp.rich > 2)
bb = binom.confint(spp.rich.3plus$species.rbcL, spp.rich.3plus$n2, methods = "exact")



# NEXT STEPS: since 'binom.confint' works on a data frame, 
# potentially melt "spp.rich.3plus" so that we can do this all in one fell swoop
# i.e. have a separate row for each taxon and marker for each level of species richness
# use 'reshape2' package for this

# then 'cbind' the results back onto the melted "spp.rich.3plus" to line results up with data
# then 'rbind' these back onto the metafor results



  
# # third step: group_by(spp.rich)
# CI.data.3 = CI.data.2 %>% group_by(spp.rich, num) %>% 
#   summarize(N = sum(N), n = n(), 
#   species.ITS = sum(species.ITS), 
#   species.rbcL = sum(species.rbcL), 
#   genus.ITS = sum(genus.ITS), 
#   genus.rbcL = sum(genus.rbcL))


################################################

# # first step: group_by(mix.ID, sample, spp.rich)
# data.rich.plots = data.species %>% 
# select(mix.ID, sample, spp.rich, qual.species.rbcL, qual.species.ITS, qual.genus.rbcL, qual.genus.ITS) %>% group_by(mix.ID, sample, spp.rich) %>% 
# summarize(species.ITS = mean(qual.species.ITS), 
#   species.rbcL = mean(qual.species.rbcL), 
#   genus.ITS = mean(qual.genus.ITS), 
#   genus.rbcL = mean(qual.genus.rbcL),
#   # variances; denoted with ".v" to disambiguate from variances in third step
#   # some of these will be "NA" but I think those shouldn't scale to the third step
#   species.ITS.v = var(qual.species.ITS), 
#   species.rbcL.v = var(qual.species.rbcL), 
#   genus.ITS.v = var(qual.genus.ITS), 
#   genus.rbcL.v = var(qual.genus.rbcL))
# 
# # second step: group_by(mix.ID, spp.rich)
# data.rich.plots = data.rich.plots %>% group_by(mix.ID, spp.rich) %>% 
#   summarize(species.ITS = mean(species.ITS), 
#   species.rbcL = mean(species.rbcL), 
#   genus.ITS = mean(genus.ITS), 
#   genus.rbcL = mean(genus.rbcL),
#   # variances; no mixes are repeated so no real variance here, just repeating from the previous
#   species.ITS.v = mean(species.ITS.v), 
#   species.rbcL.v = mean(species.rbcL.v), 
#   genus.ITS.v = mean(genus.ITS.v), 
#   genus.rbcL.v = mean(genus.rbcL.v))
# 
# 
# # third step: group_by(spp.rich); calculate CIs
# data.rich.plots = data.rich.plots %>% group_by(spp.rich) %>% 
# # summarize:
# summarize(num = n(), # start with the count
#     # means
#     species.ITS.mean = mean(species.ITS), 
#     species.rbcL.mean = mean(species.rbcL), 
#     genus.ITS.mean = mean(genus.ITS), 
#     genus.rbcL.mean = mean(genus.rbcL), 
#     # variances: for those levels of species richness with only one mix, need to use variance from previous step
#     species.ITS.var = ifelse(is.na(var(species.ITS)), mean(species.ITS.v), var(species.ITS)), 
#     species.rbcL.var = ifelse(is.na(var(species.rbcL)), mean(species.rbcL.v), var(species.rbcL)), 
#     genus.ITS.var = ifelse(is.na(var(genus.ITS)), mean(genus.ITS.v), var(genus.ITS)),
#     genus.rbcL.var = ifelse(is.na(var(genus.rbcL)), mean(genus.rbcL.v), var(genus.rbcL))) %>% 
# # mutate:
# # NEED TO MULTIPLY THESE BY 1.96 ******!!!!!!!
# mutate(species.rbcL.CI.plus = (sqrt(species.rbcL.var)/sqrt(num) + species.rbcL.mean), 
#     species.ITS.CI.plus = (sqrt(species.ITS.var)/sqrt(num) + species.ITS.mean), 
#     genus.rbcL.CI.plus = (sqrt(genus.rbcL.var)/sqrt(num) + genus.rbcL.mean), 
#     genus.ITS.CI.plus = (sqrt(genus.ITS.var)/sqrt(num) + genus.ITS.mean),
#     species.rbcL.CI.minus = (species.rbcL.mean - sqrt(species.rbcL.var)/sqrt(num)), 
#     species.ITS.CI.minus = (species.ITS.mean - sqrt(species.ITS.var)/sqrt(num)), 
#     genus.rbcL.CI.minus = (genus.rbcL.mean - sqrt(genus.rbcL.var)/sqrt(num)), 
#     genus.ITS.CI.minus = (genus.ITS.mean - sqrt(genus.ITS.var)/sqrt(num)))

# # View(data.rich.plots)
# max(data.rich.plots[,3:ncol(data.rich.plots)])
```

### Question 1: Species Richness

```{r species richness plots}
require(ggplot2)

# first going to create some made-up data to get the code for plotting down
  # then we can swap out those data for the real data to create the plots
# we ultimately want a dataframe with one row for each level of species richness (1-9)
# for each of those, we want a mean proportion as well as Â± CI

fake = data.frame(spp.rich = 1:9, n = rep(31, 9))
fake$x = fake$n - round(runif(9, min = 10, max = 30))

fakebin = binom.confint(x = fake$x, n = fake$n, methods = "logit")
fake = merge(fakebin, fake, by = c("x", "n"))
rm(fakebin)
# View(fake) # looks good

# SECOND, create plots:
limits.all <- aes(ymax = upper, ymin = lower)
spp.rich.plot <- ggplot(fake, aes(x = factor(spp.rich), y = mean))
    # (by converting spp.rich to a factor, x-axis is automatically correct)
spp.rich.plot <- spp.rich.plot + geom_point() + geom_errorbar(limits.all, width=0.2) + 
  xlab("species richness") + ylab("proportion of correct matches")
spp.rich.plot



```

**This plot is an EXAMPLE made with FAKE DATA, it is not real**

### Question 2: Rarity / % of pollen grains

thought here is to do a logistic-regression plot:

* where there are multiple values of y (successful identification) for a given x (% of pollen in a sample), then we want the mean 
* where there are not multiple values, plot the single data point (either 0 or 1)
* could also split out by species? but probably start without that
* set this up with `dplyr`: mean of successful identifications by % of pollen grains
* then need to extract the regression line from the glmer
    + check out when I've done this in the past--will need to set up a fake dataframe
    + may have code for this from the grad stats class taught spring 2016

```{r rarity plots}
require(dplyr)
require(ggplot2)

data.rarity.plot = data.species %>% select(c(10, 13:24)) %>% group_by(pollen.grain.proportion) %>% summarize(pool.num = n(),
  species.ITS = sum(qual.species.ITS), 
  species.rbcL = sum(qual.species.rbcL), 
  genus.ITS = sum(qual.genus.ITS), 
  genus.rbcL = sum(qual.genus.rbcL))

# now need to 

```







